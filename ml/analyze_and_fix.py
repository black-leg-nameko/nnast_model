#!/usr/bin/env python3
"""
çµ±åˆã‚³ãƒãƒ³ãƒ‰: ãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦GNNæ¨è«–ã‚’å®Ÿè¡Œã—ã€
OpenAI APIã§ã‚³ãƒ¼ãƒ‰ä¿®æ­£markdownã‚’ç”Ÿæˆã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚

Usage:
    python ml/analyze_and_fix.py <directory> [options]
"""
import argparse
import json
import sys
import pathlib
from pathlib import Path
from typing import Dict, List, Optional
import tempfile
from datetime import datetime
from tqdm import tqdm

# GNNæ¨è«–é–¢é€£
import torch
from ml.model import CPGTaintFlowModel
from ml.dataset import CPGGraphDataset
from ml.embed_codebert import CodeBERTEmbedder
from ml.inference import run_inference, generate_cpg_from_file, load_model, load_env_file

# LLMã‚³ãƒ¼ãƒ‰ä¿®æ­£é–¢é€£
from ml.code_fixer import LLMCodeFixer, FixSuggestion


def read_file_content(file_path: Path) -> Optional[str]:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"Warning: Could not read file {file_path}: {e}")
        return None


def generate_markdown_report(
    file_path: str,
    fix_suggestion: FixSuggestion,
    original_code: Optional[str] = None,
    confidence: Optional[float] = None,
    vulnerability_type: Optional[str] = None,
    repo_url: Optional[str] = None
) -> str:
    """
    Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        fix_suggestion: LLMãŒç”Ÿæˆã—ãŸä¿®æ­£ææ¡ˆ
        original_code: å…ƒã®ã‚³ãƒ¼ãƒ‰
        confidence: è„†å¼±æ€§æ¤œå‡ºã®ä¿¡é ¼åº¦
        vulnerability_type: è„†å¼±æ€§ã‚¿ã‚¤ãƒ—
        repo_url: ãƒªãƒã‚¸ãƒˆãƒªURLï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        Markdownå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—
    """
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    markdown = f"""# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§æ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚**: {timestamp}

## ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±

- **ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `{file_path}`
"""
    
    if repo_url:
        markdown += f"- **ãƒªãƒã‚¸ãƒˆãƒª**: {repo_url}\n"
    
    if vulnerability_type:
        markdown += f"- **è„†å¼±æ€§ã‚¿ã‚¤ãƒ—**: {vulnerability_type}\n"
    
    if confidence is not None:
        markdown += f"- **æ¤œå‡ºä¿¡é ¼åº¦**: {confidence:.2%}\n"
    
    markdown += "\n---\n\n"
    
    # å…ƒã®ã‚³ãƒ¼ãƒ‰
    if original_code:
        markdown += f"""## æ¤œå‡ºã•ã‚ŒãŸè„†å¼±ãªã‚³ãƒ¼ãƒ‰

```python
{original_code}
```

"""
    
    # ä¿®æ­£ææ¡ˆ
    markdown += f"""## ä¿®æ­£ææ¡ˆ

### ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰

```python
{fix_suggestion.fixed_code}
```

### èª¬æ˜

{fix_suggestion.explanation}

"""
    
    if fix_suggestion.vulnerability_type:
        markdown += f"**è„†å¼±æ€§ã‚¿ã‚¤ãƒ—**: {fix_suggestion.vulnerability_type}\n\n"
    
    if fix_suggestion.confidence:
        markdown += f"**ä¿®æ­£ææ¡ˆã®ä¿¡é ¼åº¦**: {fix_suggestion.confidence:.2%}\n\n"
    
    markdown += "---\n\n"
    markdown += "*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯NNASTãƒ¢ãƒ‡ãƒ«ã¨OpenAI APIã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚*\n"
    
    return markdown


def save_markdown_report(
    markdown_content: str,
    file_path: str,
    output_dir: Path
) -> Path:
    """
    Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹
    
    Args:
        markdown_content: Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        file_path: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆã«ä½¿ç”¨ï¼‰
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    
    Returns:
        ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆãƒ‘ã‚¹ã‚’å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åã«å¤‰æ›ï¼‰
    safe_name = Path(file_path).name.replace('.py', '') + '_vulnerability_report.md'
    # ãƒ‘ã‚¹ã«å«ã¾ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚‚åæ˜ ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    output_path = output_dir / safe_name
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(markdown_content)
    
    return output_path


def process_directory(
    directory: Path,
    model_path: Optional[Path],
    output_dir: Path,
    code_fixer: LLMCodeFixer,
    device: torch.device,
    batch_size: int = 32,
    min_confidence: float = 0.7
) -> Dict[str, int]:
    """
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦æ¨è«–â†’ä¿®æ­£ææ¡ˆã‚’å®Ÿè¡Œ
    
    Args:
        directory: å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_path: ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        code_fixer: LLMã‚³ãƒ¼ãƒ‰ä¿®æ­£å™¨
        device: ãƒ‡ãƒã‚¤ã‚¹
        batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
        min_confidence: æœ€å°ä¿¡é ¼åº¦é–¾å€¤
    
    Returns:
        çµ±è¨ˆæƒ…å ±ï¼ˆå‡¦ç†æ¸ˆã¿ã€ã‚¹ã‚­ãƒƒãƒ—ã€ã‚¨ãƒ©ãƒ¼ï¼‰
    """
    stats = {
        "total_files": 0,
        "processed": 0,
        "vulnerable": 0,
        "fixed": 0,
        "skipped": 0,
        "errors": 0
    }
    
    # 1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Pythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
    print(f"ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­: {directory}")
    python_files = list(directory.rglob("*.py"))
    stats["total_files"] = len(python_files)
    print(f"   è¦‹ã¤ã‹ã£ãŸPythonãƒ•ã‚¡ã‚¤ãƒ«: {len(python_files)}å€‹")
    
    if len(python_files) == 0:
        print("âš ï¸  Pythonãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return stats
    
    # 2. CPGã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    print("\nğŸ” CPGã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆä¸­...")
    with tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False) as tmp_file:
        tmp_jsonl = Path(tmp_file.name)
    
    graphs_generated = 0
    for py_file in tqdm(python_files, desc="CPGç”Ÿæˆ"):
        graph = generate_cpg_from_file(py_file)
        if graph:
            graph["file"] = str(py_file)
            with open(tmp_jsonl, "a", encoding='utf-8') as f:
                f.write(json.dumps(graph, ensure_ascii=False) + "\n")
            graphs_generated += 1
    
    print(f"   ç”Ÿæˆã•ã‚ŒãŸCPGã‚°ãƒ©ãƒ•: {graphs_generated}å€‹")
    
    if graphs_generated == 0:
        print("âŒ CPGã‚°ãƒ©ãƒ•ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return stats
    
    # 3. ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    print("\nğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    if model_path is None:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’æ¢ã™
        default_paths = [
            Path("checkpoints_test_dynamic/best_model.pt"),
            Path("checkpoints/best_model.pt"),
        ]
        model_path = None
        for path in default_paths:
            if path.exists():
                model_path = path
                break
        
        if model_path is None:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("   --model ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return stats
    
    if not model_path.exists():
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        return stats
    
    try:
        model = load_model(model_path, device)
        print(f"   âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {model_path}")
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return stats
    
    # 4. CodeBERT embedderã‚’åˆæœŸåŒ–
    print("\nğŸ“ CodeBERT embedderã‚’åˆæœŸåŒ–ä¸­...")
    embedder = CodeBERTEmbedder(device=str(device))
    
    # 5. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆä¸­...")
    dataset = CPGGraphDataset(
        graph_jsonl_path=str(tmp_jsonl),
        labels_jsonl_path=None,
        embedder=embedder,
        max_nodes=1000,
    )
    print(f"   ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚°ãƒ©ãƒ•: {len(dataset)}å€‹")
    
    if len(dataset) == 0:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒç©ºã§ã™")
        return stats
    
    # 6. GNNæ¨è«–ã‚’å®Ÿè¡Œ
    print("\nğŸ”¬ GNNæ¨è«–ã‚’å®Ÿè¡Œä¸­...")
    inference_results = run_inference(model, dataset, device, batch_size)
    stats["processed"] = len(inference_results)
    
    vulnerable_results = [r for r in inference_results if r.get("is_vulnerable", False)]
    stats["vulnerable"] = len(vulnerable_results)
    
    print(f"   å‡¦ç†æ¸ˆã¿: {len(inference_results)}å€‹")
    print(f"   è„†å¼±æ€§æ¤œå‡º: {len(vulnerable_results)}å€‹")
    
    # 7. è„†å¼±æ€§ãŒæ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦LLMã§ä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆ
    print("\nğŸ”§ ã‚³ãƒ¼ãƒ‰ä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆä¸­...")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    for result in tqdm(vulnerable_results, desc="ä¿®æ­£ææ¡ˆç”Ÿæˆ"):
        file_path = result.get("file_path", "")
        confidence = result.get("confidence", 0.0)
        vulnerability_type = result.get("vulnerability_type")
        
        # ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯
        if confidence < min_confidence:
            stats["skipped"] += 1
            continue
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
            file_path_obj = Path(file_path)
            if not file_path_obj.exists():
                print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
                stats["skipped"] += 1
                continue
            
            original_code = read_file_content(file_path_obj)
            if not original_code:
                stats["skipped"] += 1
                continue
            
            # LLMã§ä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆ
            fix_suggestion = code_fixer.generate_fix(
                vulnerable_code=original_code,
                file_path=file_path,
                vulnerability_type=vulnerability_type,
                context=f"GNNãƒ¢ãƒ‡ãƒ«ãŒä¿¡é ¼åº¦{confidence:.2%}ã§è„†å¼±æ€§ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚"
            )
            
            if not fix_suggestion:
                print(f"âš ï¸  ä¿®æ­£ææ¡ˆã®ç”Ÿæˆã«å¤±æ•—: {file_path}")
                stats["errors"] += 1
                continue
            
            # Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
            markdown = generate_markdown_report(
                file_path=file_path,
                fix_suggestion=fix_suggestion,
                original_code=original_code,
                confidence=confidence,
                vulnerability_type=vulnerability_type,
                repo_url=result.get("repo_url")
            )
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            saved_path = save_markdown_report(
                markdown_content=markdown,
                file_path=file_path,
                output_dir=output_dir
            )
            
            stats["fixed"] += 1
            print(f"   âœ… ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {saved_path}")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ ({file_path}): {e}")
            stats["errors"] += 1
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    try:
        tmp_jsonl.unlink()
    except:
        pass
    
    return stats


def main():
    parser = argparse.ArgumentParser(
        description="ãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦GNNæ¨è«–â†’ã‚³ãƒ¼ãƒ‰ä¿®æ­£markdownç”Ÿæˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä¾‹:
  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œ
  python ml/analyze_and_fix.py ./target_directory

  # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
  python ml/analyze_and_fix.py ./target_directory \\
    --model checkpoints/best_model.pt \\
    --output ./reports

  # æœ€å°ä¿¡é ¼åº¦ã‚’å¤‰æ›´
  python ml/analyze_and_fix.py ./target_directory \\
    --min-confidence 0.8
        """
    )
    
    parser.add_argument(
        "directory",
        type=Path,
        help="åˆ†æå¯¾è±¡ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹"
    )
    
    parser.add_argument(
        "--model",
        type=Path,
        default=None,
        help="ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: checkpoints_test_dynamic/best_model.pt)"
    )
    
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("vulnerability_reports"),
        help="Markdownãƒ¬ãƒãƒ¼ãƒˆã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ./vulnerability_reports)"
    )
    
    parser.add_argument(
        "--batch-size",
        type=int,
        default=32,
        help="æ¨è«–æ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 32)"
    )
    
    parser.add_argument(
        "--device",
        default=None,
        help="ãƒ‡ãƒã‚¤ã‚¹ (cuda/cpu, æœªæŒ‡å®šæ™‚ã¯è‡ªå‹•æ¤œå‡º)"
    )
    
    parser.add_argument(
        "--min-confidence",
        type=float,
        default=0.7,
        help="ä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹æœ€å°ä¿¡é ¼åº¦ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.7)"
    )
    
    parser.add_argument(
        "--llm-provider",
        default="openai",
        choices=["openai", "anthropic"],
        help="LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: openai)"
    )
    
    parser.add_argument(
        "--llm-model",
        default="gpt-4o",
        help="LLMãƒ¢ãƒ‡ãƒ«å (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt-4o)"
    )
    
    args = parser.parse_args()
    
    # ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
    load_env_file()
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    if not args.directory.exists():
        print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.directory}")
        return 1
    
    if not args.directory.is_dir():
        print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“: {args.directory}")
        return 1
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device = torch.device(
        args.device or ("cuda" if torch.cuda.is_available() else "cpu")
    )
    print(f"ğŸ–¥ï¸  ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
    
    # LLMã‚³ãƒ¼ãƒ‰ä¿®æ­£å™¨ã‚’åˆæœŸåŒ–
    print(f"\nğŸ¤– LLMã‚³ãƒ¼ãƒ‰ä¿®æ­£å™¨ã‚’åˆæœŸåŒ–ä¸­... (ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {args.llm_provider}, ãƒ¢ãƒ‡ãƒ«: {args.llm_model})")
    try:
        code_fixer = LLMCodeFixer(
            provider=args.llm_provider,
            model=args.llm_model
        )
    except Exception as e:
        print(f"âŒ LLMã‚³ãƒ¼ãƒ‰ä¿®æ­£å™¨ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        print("   .envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã¾ãŸã¯ANTHROPIC_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        return 1
    
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†
    print("\n" + "=" * 60)
    print("ğŸš€ åˆ†æã¨ä¿®æ­£ææ¡ˆã®ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 60)
    
    stats = process_directory(
        directory=args.directory,
        model_path=args.model,
        output_dir=args.output,
        code_fixer=code_fixer,
        device=device,
        batch_size=args.batch_size,
        min_confidence=args.min_confidence
    )
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_files']}")
    print(f"  å‡¦ç†æ¸ˆã¿: {stats['processed']}")
    print(f"  è„†å¼±æ€§æ¤œå‡º: {stats['vulnerable']}")
    print(f"  ä¿®æ­£ææ¡ˆç”Ÿæˆ: {stats['fixed']}")
    print(f"  ã‚¹ã‚­ãƒƒãƒ—: {stats['skipped']}")
    print(f"  ã‚¨ãƒ©ãƒ¼: {stats['errors']}")
    print(f"\nğŸ“ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å…ˆ: {args.output}")
    print("=" * 60)
    
    return 0 if stats['errors'] == 0 else 1


if __name__ == "__main__":
    sys.exit(main())

