{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NNAST Model Training on Google Colab\n",
        "\n",
        "This notebook trains the NNAST model using GPU acceleration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 環境セットアップ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU確認\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# リポジトリのクローンまたはコードのアップロード\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# 方法1: Gitリポジトリからクローン（推奨）\n",
        "# !git clone https://github.com/yourusername/nnast_model.git\n",
        "# os.chdir('nnast_model')\n",
        "\n",
        "# 方法2: zipファイルをアップロードして解凍\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# for filename in uploaded.keys():\n",
        "#     if filename.endswith('.zip'):\n",
        "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "#             zip_ref.extractall('.')\n",
        "#         print(f\"Extracted {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 依存関係のインストール\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install torch-geometric\n",
        "!pip install transformers\n",
        "!pip install tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. データセットのアップロード\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 方法1: Google Driveからマウント（推奨）\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# データセットをGoogle Driveにアップロードしてから、ここでパスを指定\n",
        "# 例: /content/drive/MyDrive/nnast_dataset/training_data\n",
        "DATASET_BASE = \"/content/drive/MyDrive/nnast_dataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 方法2: 直接アップロード（小規模データセット用）\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# \n",
        "# import zipfile\n",
        "# for filename in uploaded.keys():\n",
        "#     if filename.endswith('.zip'):\n",
        "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "#             zip_ref.extractall('.')\n",
        "#         print(f\"Extracted {filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 学習の実行\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習パラメータ\n",
        "GRAPHS_FILE = f\"{DATASET_BASE}/training_data/train_graphs.jsonl\"  # パスを調整\n",
        "LABELS_FILE = f\"{DATASET_BASE}/training_data/train_labels.jsonl\"\n",
        "OUTPUT_DIR = \"./checkpoints\"\n",
        "\n",
        "# GPU用の最適化設定\n",
        "BATCH_SIZE = 16  # GPUなら大きく設定可能（メモリに応じて調整）\n",
        "EPOCHS = 10\n",
        "MAX_NODES = 1000\n",
        "HIDDEN_DIM = 256\n",
        "LEARNING_RATE = 1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習実行\n",
        "!python3 -m ml.train \\\n",
        "    --graphs {GRAPHS_FILE} \\\n",
        "    --labels {LABELS_FILE} \\\n",
        "    --output-dir {OUTPUT_DIR} \\\n",
        "    --batch-size {BATCH_SIZE} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --hidden-dim {HIDDEN_DIM} \\\n",
        "    --max-nodes {MAX_NODES} \\\n",
        "    --device cuda \\\n",
        "    --gnn-type GAT \\\n",
        "    --lr {LEARNING_RATE}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 結果の確認とダウンロード\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習履歴の可視化\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_file = f\"{OUTPUT_DIR}/training_history.json\"\n",
        "if os.path.exists(history_file):\n",
        "    with open(history_file) as f:\n",
        "        history = json.load(f)\n",
        "    \n",
        "    plt.figure(figsize=(12, 4))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Train Acc')\n",
        "    plt.plot(history['val_acc'], label='Val Acc')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Training history file not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# チェックポイントをGoogle Driveに保存\n",
        "import shutil\n",
        "\n",
        "drive_checkpoint_dir = f\"{DATASET_BASE}/checkpoints\"\n",
        "os.makedirs(drive_checkpoint_dir, exist_ok=True)\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    # 既存のディレクトリをコピー\n",
        "    if os.path.exists(drive_checkpoint_dir):\n",
        "        shutil.rmtree(drive_checkpoint_dir)\n",
        "    shutil.copytree(OUTPUT_DIR, drive_checkpoint_dir)\n",
        "    print(f\"✓ Checkpoints saved to {drive_checkpoint_dir}\")\n",
        "else:\n",
        "    print(\"Checkpoint directory not found\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
