# データセット論文のアウトライン

**タイトル案**: "PyVulnBench: A Large-Scale Python Web Application Vulnerability Dataset for Machine Learning-Based Security Testing"

---

## 1. Abstract

- Python Webアプリケーション特化の大規模脆弱性データセット
- OWASP Top 10との整合性
- 実在データ + 合成データのハイブリッドアプローチ
- 5,000-10,000サンプル規模
- ベンチマークとしての価値

---

## 2. Introduction

### 2.1 背景
- 機械学習ベースの脆弱性検出の重要性
- 既存データセットの課題（C/C++中心、Python Web特化が不足）
- Python Webアプリケーションの普及とセキュリティの重要性

### 2.2 貢献
1. **大規模データセット**: 5,000-10,000サンプル
2. **Python Web特化**: Django/Flask/FastAPI対応
3. **OWASP Top 10整合**: 実用的な脆弱性カテゴリを網羅
4. **再現可能な構築手法**: ハイブリッドアプローチ
5. **ベンチマークとしての価値**: 標準データセット

### 2.3 論文構成

---

## 3. Related Work

### 3.1 既存の脆弱性データセット
- **BigVul**: C/C++中心、95,000+サンプル
- **Devign**: C/C++中心、27,000+サンプル
- **CodeXGLUE**: 多言語、10,000+サンプル
- **Python特化データセット**: 現状、大規模データセットが存在しない

### 3.2 脆弱性検出手法
- 静的解析ベース
- 機械学習ベース
- グラフニューラルネットワークベース

### 3.3 データセット構築手法
- 実在データ収集
- 合成データ生成
- データ拡張

---

## 4. Dataset Construction Methodology

### 4.1 データセット設計原則
1. **Python Web特化**: Django/Flask/FastAPI
2. **OWASP Top 10整合**: 実用的な脆弱性カテゴリ
3. **品質保証**: 手動検証と自動チェック
4. **再現可能性**: 構築手法の明示

### 4.2 データ収集戦略

#### 4.2.1 実在データの収集
- **CVE関連コミット**: GitHubからCVE参照を含むコミットを収集
- **GitHub Security Advisories**: GHSAからPythonプロジェクトを抽出
- **セキュリティ修正コミット**: 多様なクエリパターンで収集
- **特定脆弱性タイプ**: OWASP Top 10カテゴリ別に収集
- **セキュリティプロジェクト**: OWASP、CTF、セキュリティツールのテストケース

#### 4.2.2 合成データの生成
- **テンプレートベース生成**: 15パターンID用のテンプレート
- **フレームワーク別バリエーション**: Flask/Django/FastAPI
- **複雑度のバリエーション**: シンプル/中程度/複雑
- **バランス調整**: パターンID別の均等な分布

#### 4.2.3 データ拡張
- **コード変換**: 変数名の変更、コメントの追加/削除
- **制御フロー変更**: if文の追加、ループの変更
- **関数の分割/統合**: コード構造の変更

### 4.3 データ品質保証

#### 4.3.1 自動品質チェック
- Graph-Label Alignment
- Pattern Distribution
- Framework Distribution
- Source/Sink Coverage
- CPG Quality
- 重複検出

#### 4.3.2 手動検証
- 各パターンIDからランダムに10-20サンプルを抽出
- 専門家による脆弱性の有無の検証
- 誤ラベルの修正

#### 4.3.3 データクリーニング
- 重複の除去
- 品質の低いサンプルの除去
- パターンIDの再分類

### 4.4 データセット統合とバランス調整

#### 4.4.1 統合戦略
- 実在データ: 60-70%
- 合成データ: 20-30%
- 拡張データ: 10%

#### 4.4.2 バランス調整
- パターンID別: 各パターンで200-400サンプル
- フレームワーク別: Flask 40%, Django 30%, FastAPI 30%
- 複雑度: シンプル 40%, 中程度 40%, 複雑 20%
- ラベル: 脆弱 50%, 安全 50%

#### 4.4.3 データセット分割
- **Project-split**: 同一リポジトリは片側のみ
- **Time-split**: 修正コミットは時系列で分割
- Train/Val/Test: 70%/15%/15%

---

## 5. Dataset Statistics

### 5.1 基本統計
- 総サンプル数: 5,000-10,000
- Train/Val/Test分割
- ラベル分布（脆弱/安全）

### 5.2 パターンID別分布
- 15パターンIDの分布
- 各パターンでのサンプル数

### 5.3 フレームワーク別分布
- Flask/Django/FastAPIの分布

### 5.4 複雑度別分布
- シンプル/中程度/複雑の分布

### 5.5 ソース別分布
- 実在データ/合成データ/拡張データの分布

### 5.6 品質指標
- Source/Sink coverage
- CPG Quality
- 手動検証精度

---

## 6. Dataset Evaluation

### 6.1 ベースライン性能
- 既存手法（ルールベース、単純ML）との比較
- データセットの難易度分析

### 6.2 データセットの多様性
- パターンID別の多様性
- フレームワーク別の多様性
- 複雑度別の多様性

### 6.3 データセットの実用性
- 実在データの割合
- 実在プロジェクトでの使用例

---

## 7. Case Studies

### 7.1 データセットを使用した研究例
- GNNベースの脆弱性検出
- 他の機械学習手法との比較

### 7.2 データセットの拡張例
- 新しいパターンIDの追加
- 新しいフレームワークの対応

---

## 8. Limitations and Future Work

### 8.1 制限事項
- 静的解析で判定可能な脆弱性のみ
- 動的挙動依存の脆弱性は対象外
- 合成データと実在データの分布差

### 8.2 今後の拡張
- データセットの継続的な拡張
- 新しいパターンIDの追加
- 新しいフレームワークの対応
- データセットの品質向上

---

## 9. Conclusion

- Python Web特化の大規模脆弱性データセットを構築
- OWASP Top 10との整合性
- 再現可能な構築手法
- ベンチマークとしての価値
- コミュニティへの貢献

---

## 10. Dataset Availability

- データセットの公開場所
- 使用ライセンス
- データセットのダウンロード方法
- データセットの更新履歴

---

## 付録

### A. データセット仕様書
- データセットの詳細仕様
- ファイル形式
- メタデータの説明

### B. 構築手法の詳細
- 収集ツールの実装詳細
- 品質保証プロセスの詳細
- データ拡張手法の詳細

### C. 評価結果の詳細
- ベースライン性能の詳細結果
- データセットの多様性分析の詳細

---

## 参考文献

- BigVul, Devign, CodeXGLUE等の既存データセット
- OWASP Top 10
- 脆弱性検出手法の関連研究
- データセット構築手法の関連研究

